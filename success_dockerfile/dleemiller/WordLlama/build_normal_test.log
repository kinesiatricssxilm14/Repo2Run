#0 building with "default" instance using docker driver

#1 [internal] load build definition from Dockerfile
#1 transferring dockerfile: 1.05kB done
#1 DONE 0.0s

#2 [internal] load metadata for docker.io/library/python:3.10
#2 DONE 0.0s

#3 [internal] load .dockerignore
#3 transferring context: 2B done
#3 DONE 0.0s

#4 [1/5] FROM docker.io/library/python:3.10
#4 DONE 0.0s

#5 [2/5] RUN mkdir -p ~/.pip && touch ~/.pip/pip.conf &&     echo "[global]" >> ~/.pip/pip.conf && echo "index-url=http://simple/" >> ~/.pip/pip.conf && echo "[install]" >> ~/.pip/pip.conf && echo "trusted-host=pypi..org" >> ~/.pip/pip.conf &&     apt-get update && apt-get install -y curl &&     curl -sSL https://install.python-poetry.org | python -
#5 CACHED

#6 [3/5] RUN pip install pytest pytest-xdist &&     pip install pipdeptree &&     git clone https://github.com/dleemiller/WordLlama.git &&     mkdir /repo &&     git config --global --add safe.directory /repo &&     cp -r /WordLlama/. /repo && rm -rf /WordLlama/ &&     rm -rf /WordLlama &&     cd /repo && git checkout e38d4760a7e974d02d2556148d95b9053555d82d &&     pip install -e /repo
#6 1.765 Looking in indexes: http://simple/
#6 1.926 Collecting pytest
#6 1.948   Downloading http://packages/pytest/pytest-8.3.4-py3-none-any.whl (343 kB)
#6 1.974      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 343.1/343.1 kB 16.3 MB/s eta 0:00:00
#6 2.052 Collecting pytest-xdist
#6 2.072   Downloading http://packages/pytest-xdist/pytest_xdist-3.6.1-py3-none-any.whl (46 kB)
#6 2.081      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.1/46.1 kB 8.8 MB/s eta 0:00:00
#6 2.147 Collecting exceptiongroup>=1.0.0rc8
#6 2.165   Downloading http://packages/exceptiongroup/exceptiongroup-1.2.2-py3-none-any.whl (16 kB)
#6 2.222 Collecting pluggy<2,>=1.5
#6 2.241   Downloading http://packages/pluggy/pluggy-1.5.0-py3-none-any.whl (20 kB)
#6 2.276 Collecting iniconfig
#6 2.295   Downloading http://packages/iniconfig/iniconfig-2.0.0-py3-none-any.whl (5.9 kB)
#6 2.366 Collecting packaging
#6 2.385   Downloading http://packages/packaging/packaging-24.2-py3-none-any.whl (65 kB)
#6 2.398      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.5/65.5 kB 7.3 MB/s eta 0:00:00
#6 2.457 Collecting tomli>=1
#6 2.478   Downloading http://packages/tomli/tomli-2.2.1-py3-none-any.whl (14 kB)
#6 2.554 Collecting execnet>=2.1
#6 2.577   Downloading http://packages/execnet/execnet-2.1.1-py3-none-any.whl (40 kB)
#6 2.586      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.6/40.6 kB 7.1 MB/s eta 0:00:00
#6 2.765 Installing collected packages: tomli, pluggy, packaging, iniconfig, execnet, exceptiongroup, pytest, pytest-xdist
#6 3.549 Successfully installed exceptiongroup-1.2.2 execnet-2.1.1 iniconfig-2.0.0 packaging-24.2 pluggy-1.5.0 pytest-8.3.4 pytest-xdist-3.6.1 tomli-2.2.1
#6 3.552 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
#6 3.750 
#6 3.750 [notice] A new release of pip is available: 23.0.1 -> 24.3.1
#6 3.750 [notice] To update, run: pip install --upgrade pip
#6 4.527 Looking in indexes: http://simple/
#6 4.622 Collecting pipdeptree
#6 4.643   Downloading http://packages/pipdeptree/pipdeptree-2.24.0-py3-none-any.whl (32 kB)
#6 4.671 Requirement already satisfied: packaging>=24.1 in /usr/local/lib/python3.10/site-packages (from pipdeptree) (24.2)
#6 4.832 Collecting pip>=24.2
#6 4.851   Using cached http://packages/pip/pip-24.3.1-py3-none-any.whl (1.8 MB)
#6 4.975 Installing collected packages: pip, pipdeptree
#6 4.975   Attempting uninstall: pip
#6 4.976     Found existing installation: pip 23.0.1
#6 5.146     Uninstalling pip-23.0.1:
#6 5.331       Successfully uninstalled pip-23.0.1
#6 6.558 Successfully installed pip-24.3.1 pipdeptree-2.24.0
#6 6.558 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
#6 6.729 Cloning into 'WordLlama'...
#6 12.36 Note: switching to 'e38d4760a7e974d02d2556148d95b9053555d82d'.
#6 12.36 
#6 12.36 You are in 'detached HEAD' state. You can look around, make experimental
#6 12.36 changes and commit them, and you can discard any commits you make in this
#6 12.36 state without impacting any branches by switching back to a branch.
#6 12.36 
#6 12.36 If you want to create a new branch to retain commits you create, you may
#6 12.36 do so (now or later) by using -c with the switch command. Example:
#6 12.36 
#6 12.36   git switch -c <new-branch-name>
#6 12.36 
#6 12.36 Or undo this operation with:
#6 12.36 
#6 12.36   git switch -
#6 12.36 
#6 12.36 Turn off this advice by setting config variable advice.detachedHead to false
#6 12.36 
#6 12.36 HEAD is now at e38d476 Update README.md
#6 12.90 Looking in indexes: http://simple/
#6 12.90 Obtaining file:///repo
#6 12.91   Installing build dependencies: started
#6 21.09   Installing build dependencies: finished with status 'done'
#6 21.09   Checking if build backend supports build_editable: started
#6 21.37   Checking if build backend supports build_editable: finished with status 'done'
#6 21.37   Getting requirements to build editable: started
#6 29.76   Getting requirements to build editable: finished with status 'done'
#6 29.76   Preparing editable metadata (pyproject.toml): started
#6 31.07   Preparing editable metadata (pyproject.toml): finished with status 'done'
#6 31.51 Collecting numpy>=2 (from wordllama==0.3.7.post1)
#6 31.52   Using cached http://packages/numpy/numpy-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)
#6 31.93 Collecting safetensors (from wordllama==0.3.7.post1)
#6 31.95   Downloading http://packages/safetensors/safetensors-0.5.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)
#6 32.38 Collecting tokenizers (from wordllama==0.3.7.post1)
#6 32.40   Downloading http://packages/tokenizers/tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)
#6 32.45      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 79.8 MB/s eta 0:00:00
#6 32.49 Collecting toml (from wordllama==0.3.7.post1)
#6 32.51   Downloading http://packages/toml/toml-0.10.2-py2.py3-none-any.whl (16 kB)
#6 32.79 Collecting pydantic>=2 (from wordllama==0.3.7.post1)
#6 32.81   Downloading http://packages/pydantic/pydantic-2.10.4-py3-none-any.whl (431 kB)
#6 32.93 Collecting requests (from wordllama==0.3.7.post1)
#6 32.93   Using cached http://packages/requests/requests-2.32.3-py3-none-any.whl (64 kB)
#6 32.96 Collecting annotated-types>=0.6.0 (from pydantic>=2->wordllama==0.3.7.post1)
#6 32.99   Downloading http://packages/annotated-types/annotated_types-0.7.0-py3-none-any.whl (13 kB)
#6 34.31 Collecting pydantic-core==2.27.2 (from pydantic>=2->wordllama==0.3.7.post1)
#6 34.33   Downloading http://packages/pydantic-core/pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)
#6 34.37      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 76.7 MB/s eta 0:00:00
#6 34.41 Collecting typing-extensions>=4.12.2 (from pydantic>=2->wordllama==0.3.7.post1)
#6 34.43   Downloading http://packages/typing-extensions/typing_extensions-4.12.2-py3-none-any.whl (37 kB)
#6 34.63 Collecting charset-normalizer<4,>=2 (from requests->wordllama==0.3.7.post1)
#6 34.63   Using cached http://packages/charset-normalizer/charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (146 kB)
#6 34.68 Collecting idna<4,>=2.5 (from requests->wordllama==0.3.7.post1)
#6 34.68   Using cached http://packages/idna/idna-3.10-py3-none-any.whl (70 kB)
#6 34.77 Collecting urllib3<3,>=1.21.1 (from requests->wordllama==0.3.7.post1)
#6 34.78   Using cached http://packages/urllib3/urllib3-2.3.0-py3-none-any.whl (128 kB)
#6 34.82 Collecting certifi>=2017.4.17 (from requests->wordllama==0.3.7.post1)
#6 34.83   Using cached http://packages/certifi/certifi-2024.12.14-py3-none-any.whl (164 kB)
#6 35.02 Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers->wordllama==0.3.7.post1)
#6 35.04   Downloading http://packages/huggingface-hub/huggingface_hub-0.27.1-py3-none-any.whl (450 kB)
#6 35.18 Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers->wordllama==0.3.7.post1)
#6 35.18   Using cached http://packages/filelock/filelock-3.16.1-py3-none-any.whl (16 kB)
#6 35.24 Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers->wordllama==0.3.7.post1)
#6 35.26   Downloading http://packages/fsspec/fsspec-2024.12.0-py3-none-any.whl (183 kB)
#6 35.34 Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->wordllama==0.3.7.post1) (24.2)
#6 35.47 Collecting pyyaml>=5.1 (from huggingface-hub<1.0,>=0.16.4->tokenizers->wordllama==0.3.7.post1)
#6 35.49   Downloading http://packages/pyyaml/PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)
#6 35.52      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 751.2/751.2 kB 38.0 MB/s eta 0:00:00
#6 35.63 Collecting tqdm>=4.42.1 (from huggingface-hub<1.0,>=0.16.4->tokenizers->wordllama==0.3.7.post1)
#6 35.66   Downloading http://packages/tqdm/tqdm-4.67.1-py3-none-any.whl (78 kB)
#6 35.70 Building wheels for collected packages: wordllama
#6 35.70   Building editable for wordllama (pyproject.toml): started
#6 95.80   Building editable for wordllama (pyproject.toml): finished with status 'done'
#6 95.80   Created wheel for wordllama: filename=wordllama-0.3.7.post1-0.editable-cp310-cp310-linux_x86_64.whl size=9041 sha256=97ba2905089617c068d7fe8a9c307d67341d6dfb2bccb90c87c22ce4ddf704e4
#6 95.80   Stored in directory: /tmp/pip-ephem-wheel-cache-7a4akorf/wheels/83/05/69/977b54e69478800cfcea8a9437a7ea4a9b1a48db334f824611
#6 95.80 Successfully built wordllama
#6 95.99 Installing collected packages: urllib3, typing-extensions, tqdm, toml, safetensors, pyyaml, numpy, idna, fsspec, filelock, charset-normalizer, certifi, annotated-types, requests, pydantic-core, pydantic, huggingface-hub, tokenizers, wordllama
#6 100.9 Successfully installed annotated-types-0.7.0 certifi-2024.12.14 charset-normalizer-3.4.1 filelock-3.16.1 fsspec-2024.12.0 huggingface-hub-0.27.1 idna-3.10 numpy-2.2.1 pydantic-2.10.4 pydantic-core-2.27.2 pyyaml-6.0.2 requests-2.32.3 safetensors-0.5.1 tokenizers-0.21.0 toml-0.10.2 tqdm-4.67.1 typing-extensions-4.12.2 urllib3-2.3.0 wordllama-0.3.7.post1
#6 100.9 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
#6 DONE 102.0s

#7 [4/5] RUN cd /repo && pytest --collect-only -q
#7 1.439 tests/test_functional.py::TestFunctional::test_function_clustering
#7 1.439 tests/test_functional.py::TestFunctional::test_function_similarity
#7 1.439 tests/test_functional.py::TestFunctional::test_function_similarity_binary
#7 1.439 tests/test_inference.py::TestWordLlamaInference::test_binarization_and_packing
#7 1.439 tests/test_inference.py::TestWordLlamaInference::test_cluster_fails_binary
#7 1.439 tests/test_inference.py::TestWordLlamaInference::test_deduplicate_all_duplicates
#7 1.439 tests/test_inference.py::TestWordLlamaInference::test_deduplicate_cosine
#7 1.439 tests/test_inference.py::TestWordLlamaInference::test_deduplicate_no_duplicates
#7 1.439 tests/test_inference.py::TestWordLlamaInference::test_deduplicate_return_indices
#7 1.439 tests/test_inference.py::TestWordLlamaInference::test_embed
#7 1.439 tests/test_inference.py::TestWordLlamaInference::test_error_on_wrong_embedding_type
#7 1.439 tests/test_inference.py::TestWordLlamaInference::test_instantiate_with_truncation
#7 1.439 tests/test_inference.py::TestWordLlamaInference::test_normalization_effect
#7 1.439 tests/test_inference.py::TestWordLlamaInference::test_rank_cosine
#7 1.439 tests/test_inference.py::TestWordLlamaInference::test_rank_hamming
#7 1.439 tests/test_inference.py::TestWordLlamaInference::test_similarity_cosine
#7 1.439 tests/test_inference.py::TestWordLlamaInference::test_similarity_hamming
#7 1.439 tests/test_inference.py::TestWordLlamaInference::test_split_fails_binary
#7 1.439 tests/test_inference.py::TestWordLlamaInference::test_tokenize
#7 1.439 tests/test_kmeans.py::TestKMeansClustering::test_kmeans_clustering_convergence
#7 1.439 tests/test_kmeans.py::TestKMeansClustering::test_kmeans_clustering_different_initializations
#7 1.439 tests/test_kmeans.py::TestKMeansClustering::test_kmeans_clustering_different_k
#7 1.439 tests/test_kmeans.py::TestKMeansClustering::test_kmeans_clustering_labels
#7 1.439 tests/test_kmeans.py::TestKMeansClustering::test_kmeans_clustering_random_state
#7 1.439 tests/test_minima_functions.py::TestSavitzkyGolay::test_find_local_minima
#7 1.439 tests/test_minima_functions.py::TestSavitzkyGolay::test_find_local_minima_invalid_polynomial_order
#7 1.439 tests/test_minima_functions.py::TestSavitzkyGolay::test_find_local_minima_invalid_window_size
#7 1.439 tests/test_minima_functions.py::TestWindowedCrossSimilarity::test_windowed_cross_similarity
#7 1.439 tests/test_minima_functions.py::TestWindowedCrossSimilarity::test_windowed_cross_similarity_invalid_window
#7 1.439 tests/test_minima_functions.py::TestWindowedCrossSimilarity::test_windowed_cross_similarity_small_window
#7 1.439 tests/test_semantic_splitter.py::TestSemanticSplitter::test_constrained_split
#7 1.439 tests/test_semantic_splitter.py::TestSemanticSplitter::test_flatten
#7 1.439 tests/test_semantic_splitter.py::TestSemanticSplitter::test_reconstruct
#7 1.439 tests/test_semantic_splitter.py::TestSemanticSplitter::test_reconstruct_return_minima
#7 1.439 tests/test_semantic_splitter.py::TestSemanticSplitter::test_split
#7 1.439 tests/test_splitting_functions.py::TestSplitter::test_constrained_batches
#7 1.439 tests/test_splitting_functions.py::TestSplitter::test_constrained_coalesce
#7 1.439 tests/test_splitting_functions.py::TestSplitter::test_reverse_merge
#7 1.439 tests/test_splitting_functions.py::TestSplitter::test_split_sentences
#7 1.439 tests/test_vector_similarity.py::TestVectorSimilarity::test_binarization_and_packing
#7 1.439 tests/test_vector_similarity.py::TestVectorSimilarity::test_cosine_similarity_direct
#7 1.439 tests/test_vector_similarity.py::TestVectorSimilarity::test_hamming_similarity_direct
#7 1.439 tests/test_wordllama.py::TestWordLlama::test_load_tokenizer_fallback
#7 1.439 tests/test_wordllama.py::TestWordLlama::test_load_with_custom_cache_dir
#7 1.439 tests/test_wordllama.py::TestWordLlama::test_load_with_default_cache_dir
#7 1.439 tests/test_wordllama.py::TestWordLlama::test_load_with_disable_download
#7 1.439 tests/test_wordllama.py::TestWordLlama::test_load_with_truncated_dimension
#7 1.439 tests/test_wordllama.py::TestWordLlama::test_resolve_file_downloads_if_not_found
#7 1.439 
#7 1.439 48 tests collected in 0.56s
#7 DONE 1.7s

#8 exporting to image
#8 exporting layers
#8 exporting layers 1.5s done
#8 writing image sha256:f56ac673f6e8e8032534fa8f40279d6ace43e31dbd33b8d35b710577a4a1ddbd done
#8 naming to docker.io/library/tmp:tmp done
#8 DONE 1.5s
