#0 building with "default" instance using docker driver

#1 [internal] load build definition from Dockerfile
#1 transferring dockerfile: 1.11kB done
#1 DONE 0.0s

#2 [internal] load metadata for docker.io/library/python:3.10
#2 DONE 0.0s

#3 [internal] load .dockerignore
#3 transferring context: 2B done
#3 DONE 0.0s

#4 [1/5] FROM docker.io/library/python:3.10
#4 DONE 0.0s

#5 [2/5] RUN mkdir -p ~/.pip && touch ~/.pip/pip.conf &&     echo "[global]" >> ~/.pip/pip.conf && echo "index-url=http://simple/" >> ~/.pip/pip.conf && echo "[install]" >> ~/.pip/pip.conf && echo "trusted-host=pypi..org" >> ~/.pip/pip.conf &&     apt-get update && apt-get install -y curl &&     curl -sSL https://install.python-poetry.org | python -
#5 CACHED

#6 [3/5] RUN pip install pytest pytest-xdist &&     pip install pipdeptree &&     git clone https://github.com/zipnn/zipnn.git &&     mkdir /repo &&     git config --global --add safe.directory /repo &&     cp -r /zipnn/. /repo && rm -rf /zipnn/ &&     rm -rf /zipnn &&     cd /repo && git checkout 187f336b6790cc66d1248befa52066937d185afd &&     cd /repo && pip install -e . &&     cd /repo && python3 -m unittest discover -s tests/ -p test_suit.py
#6 1.698 Looking in indexes: http://simple/
#6 1.864 Collecting pytest
#6 1.895   Downloading http://packages/pytest/pytest-8.3.4-py3-none-any.whl (343 kB)
#6 1.925      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 343.1/343.1 kB 14.1 MB/s eta 0:00:00
#6 1.999 Collecting pytest-xdist
#6 2.017   Downloading http://packages/pytest-xdist/pytest_xdist-3.6.1-py3-none-any.whl (46 kB)
#6 2.029      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.1/46.1 kB 4.4 MB/s eta 0:00:00
#6 2.092 Collecting exceptiongroup>=1.0.0rc8
#6 2.110   Downloading http://packages/exceptiongroup/exceptiongroup-1.2.2-py3-none-any.whl (16 kB)
#6 2.178 Collecting packaging
#6 2.199   Downloading http://packages/packaging/packaging-24.2-py3-none-any.whl (65 kB)
#6 2.212      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.5/65.5 kB 6.7 MB/s eta 0:00:00
#6 2.275 Collecting tomli>=1
#6 2.305   Downloading http://packages/tomli/tomli-2.2.1-py3-none-any.whl (14 kB)
#6 2.340 Collecting iniconfig
#6 2.363   Downloading http://packages/iniconfig/iniconfig-2.0.0-py3-none-any.whl (5.9 kB)
#6 2.411 Collecting pluggy<2,>=1.5
#6 2.443   Downloading http://packages/pluggy/pluggy-1.5.0-py3-none-any.whl (20 kB)
#6 2.496 Collecting execnet>=2.1
#6 2.514   Downloading http://packages/execnet/execnet-2.1.1-py3-none-any.whl (40 kB)
#6 2.522      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.6/40.6 kB 7.3 MB/s eta 0:00:00
#6 2.662 Installing collected packages: tomli, pluggy, packaging, iniconfig, execnet, exceptiongroup, pytest, pytest-xdist
#6 3.216 Successfully installed exceptiongroup-1.2.2 execnet-2.1.1 iniconfig-2.0.0 packaging-24.2 pluggy-1.5.0 pytest-8.3.4 pytest-xdist-3.6.1 tomli-2.2.1
#6 3.217 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
#6 3.338 
#6 3.338 [notice] A new release of pip is available: 23.0.1 -> 24.3.1
#6 3.338 [notice] To update, run: pip install --upgrade pip
#6 4.033 Looking in indexes: http://simple/
#6 4.117 Collecting pipdeptree
#6 4.137   Downloading http://packages/pipdeptree/pipdeptree-2.24.0-py3-none-any.whl (32 kB)
#6 4.295 Collecting pip>=24.2
#6 4.306   Using cached http://packages/pip/pip-24.3.1-py3-none-any.whl (1.8 MB)
#6 4.326 Requirement already satisfied: packaging>=24.1 in /usr/local/lib/python3.10/site-packages (from pipdeptree) (24.2)
#6 4.443 Installing collected packages: pip, pipdeptree
#6 4.443   Attempting uninstall: pip
#6 4.445     Found existing installation: pip 23.0.1
#6 4.616     Uninstalling pip-23.0.1:
#6 4.774       Successfully uninstalled pip-23.0.1
#6 6.018 Successfully installed pip-24.3.1 pipdeptree-2.24.0
#6 6.019 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
#6 6.189 Cloning into 'zipnn'...
#6 9.683 Note: switching to '187f336b6790cc66d1248befa52066937d185afd'.
#6 9.683 
#6 9.683 You are in 'detached HEAD' state. You can look around, make experimental
#6 9.683 changes and commit them, and you can discard any commits you make in this
#6 9.683 state without impacting any branches by switching back to a branch.
#6 9.683 
#6 9.683 If you want to create a new branch to retain commits you create, you may
#6 9.683 do so (now or later) by using -c with the switch command. Example:
#6 9.683 
#6 9.683   git switch -c <new-branch-name>
#6 9.683 
#6 9.683 Or undo this operation with:
#6 9.683 
#6 9.683   git switch -
#6 9.683 
#6 9.683 Turn off this advice by setting config variable advice.detachedHead to false
#6 9.683 
#6 9.683 HEAD is now at 187f336 Update README.md
#6 10.21 Looking in indexes: http://simple/
#6 10.21 Obtaining file:///repo
#6 10.21   Preparing metadata (setup.py): started
#6 21.68   Preparing metadata (setup.py): finished with status 'done'
#6 22.12 Collecting numpy (from zipnn==0.4.0)
#6 22.14   Downloading http://packages/numpy/numpy-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)
#6 22.26      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.4/16.4 MB 167.0 MB/s eta 0:00:00
#6 22.48 Collecting zstandard (from zipnn==0.4.0)
#6 22.51   Downloading http://packages/zstandard/zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)
#6 22.56      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 130.6 MB/s eta 0:00:00
#6 22.69 Collecting torch (from zipnn==0.4.0)
#6 22.70   Downloading http://packages/torch/torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)
#6 30.76      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 906.4/906.4 MB 44.6 MB/s eta 0:00:00
#6 33.86 Collecting filelock (from torch->zipnn==0.4.0)
#6 33.86   Using cached http://packages/filelock/filelock-3.16.1-py3-none-any.whl (16 kB)
#6 33.91 Collecting typing-extensions>=4.8.0 (from torch->zipnn==0.4.0)
#6 33.93   Downloading http://packages/typing-extensions/typing_extensions-4.12.2-py3-none-any.whl (37 kB)
#6 34.01 Collecting networkx (from torch->zipnn==0.4.0)
#6 34.03   Downloading http://packages/networkx/networkx-3.4.2-py3-none-any.whl (1.7 MB)
#6 34.07      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 61.1 MB/s eta 0:00:00
#6 34.14 Collecting jinja2 (from torch->zipnn==0.4.0)
#6 34.16   Downloading http://packages/jinja2/jinja2-3.1.5-py3-none-any.whl (134 kB)
#6 34.23 Collecting fsspec (from torch->zipnn==0.4.0)
#6 34.25   Downloading http://packages/fsspec/fsspec-2024.12.0-py3-none-any.whl (183 kB)
#6 34.35 Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->zipnn==0.4.0)
#6 34.38   Downloading http://packages/nvidia-cuda-nvrtc-cu12/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)
#6 34.54      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.6/24.6 MB 173.7 MB/s eta 0:00:00
#6 34.65 Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->zipnn==0.4.0)
#6 34.67   Downloading http://packages/nvidia-cuda-runtime-cu12/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)
#6 34.71      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 883.7/883.7 kB 37.8 MB/s eta 0:00:00
#6 34.74 Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->zipnn==0.4.0)
#6 34.76   Downloading http://packages/nvidia-cuda-cupti-cu12/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)
#6 34.86      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.8/13.8 MB 165.5 MB/s eta 0:00:00
#6 34.94 Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->zipnn==0.4.0)
#6 34.96   Downloading http://packages/nvidia-cudnn-cu12/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)
#6 44.08      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 31.9 MB/s eta 0:00:00
#6 46.28 Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->zipnn==0.4.0)
#6 46.31   Downloading http://packages/nvidia-cublas-cu12/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)
#6 51.88      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 363.4/363.4 MB 50.0 MB/s eta 0:00:00
#6 53.12 Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->zipnn==0.4.0)
#6 53.14   Downloading http://packages/nvidia-cufft-cu12/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)
#6 54.28      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.5/211.5 MB 185.8 MB/s eta 0:00:00
#6 54.98 Collecting nvidia-curand-cu12==10.3.5.147 (from torch->zipnn==0.4.0)
#6 54.99   Downloading http://packages/nvidia-curand-cu12/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)
#6 55.37      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 181.5 MB/s eta 0:00:00
#6 55.64 Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->zipnn==0.4.0)
#6 55.66   Downloading http://packages/nvidia-cusolver-cu12/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)
#6 56.43      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 127.9/127.9 MB 171.1 MB/s eta 0:00:00
#6 56.86 Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->zipnn==0.4.0)
#6 56.88   Downloading http://packages/nvidia-cusparse-cu12/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)
#6 58.20      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.5/207.5 MB 159.0 MB/s eta 0:00:00
#6 58.87 Collecting nvidia-nccl-cu12==2.21.5 (from torch->zipnn==0.4.0)
#6 58.89   Downloading http://packages/nvidia-nccl-cu12/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)
#6 59.83      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 188.7/188.7 MB 203.6 MB/s eta 0:00:00
#6 60.46 Collecting nvidia-nvtx-cu12==12.4.127 (from torch->zipnn==0.4.0)
#6 60.48   Downloading http://packages/nvidia-nvtx-cu12/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)
#6 60.54 Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->zipnn==0.4.0)
#6 60.56   Downloading http://packages/nvidia-nvjitlink-cu12/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)
#6 60.70      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.1/21.1 MB 165.4 MB/s eta 0:00:00
#6 60.80 Collecting triton==3.1.0 (from torch->zipnn==0.4.0)
#6 60.83   Downloading http://packages/triton/triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)
#6 61.92      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.5/209.5 MB 195.7 MB/s eta 0:00:00
#6 62.62 Collecting sympy==1.13.1 (from torch->zipnn==0.4.0)
#6 62.64   Downloading http://packages/sympy/sympy-1.13.1-py3-none-any.whl (6.2 MB)
#6 62.74      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.2/6.2 MB 71.8 MB/s eta 0:00:00
#6 62.91 Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch->zipnn==0.4.0)
#6 62.93   Downloading http://packages/mpmath/mpmath-1.3.0-py3-none-any.whl (536 kB)
#6 62.95      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 24.3 MB/s eta 0:00:00
#6 63.10 Collecting MarkupSafe>=2.0 (from jinja2->torch->zipnn==0.4.0)
#6 63.12   Downloading http://packages/markupsafe/MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)
#6 63.44 Installing collected packages: mpmath, zstandard, typing-extensions, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, zipnn
#6 145.1   DEPRECATION: Legacy editable install of zipnn==0.4.0 from file:///repo (setup.py develop) is deprecated. pip 25.0 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457
#6 145.1   Running setup.py develop for zipnn
#6 152.4 Successfully installed MarkupSafe-3.0.2 filelock-3.16.1 fsspec-2024.12.0 jinja2-3.1.5 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.1 triton-3.1.0 typing-extensions-4.12.2 zipnn zstandard-0.23.0
#6 152.4 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
#6 158.5 ..
#6 158.5 ----------------------------------------------------------------------
#6 158.5 Ran 2 tests in 2.501s
#6 158.5 
#6 158.5 OK
#6 158.5 
#6 158.5 Testing size: 255KB
#6 158.5 Are the original and decompressed byte strings the same [TORCH]?  True
#6 158.5 Are the original and decompressed byte strings the same [BYTES]?  True
#6 158.5 
#6 158.5 Testing size: 256KB
#6 158.5 Are the original and decompressed byte strings the same [TORCH]?  True
#6 158.5 Are the original and decompressed byte strings the same [BYTES]?  True
#6 158.5 
#6 158.5 Testing size: 257KB
#6 158.5 Are the original and decompressed byte strings the same [TORCH]?  True
#6 158.5 Are the original and decompressed byte strings the same [BYTES]?  True
#6 158.5 
#6 158.5 Testing size: 511KB
#6 158.5 Are the original and decompressed byte strings the same [TORCH]?  True
#6 158.5 Are the original and decompressed byte strings the same [BYTES]?  True
#6 158.5 
#6 158.5 Testing size: 512KB
#6 158.5 Are the original and decompressed byte strings the same [TORCH]?  True
#6 158.5 Are the original and decompressed byte strings the same [BYTES]?  True
#6 158.5 
#6 158.5 Testing size: 513KB
#6 158.5 Are the original and decompressed byte strings the same [TORCH]?  True
#6 158.5 Are the original and decompressed byte strings the same [BYTES]?  True
#6 158.5 
#6 158.5 Testing size: 1024KB
#6 158.5 Are the original and decompressed byte strings the same [TORCH]?  True
#6 158.5 Are the original and decompressed byte strings the same [BYTES]?  True
#6 158.5 
#6 158.5 Testing size: 0.99MB
#6 158.5 Are the original and decompressed byte strings the same [TORCH]?  True
#6 158.5 Are the original and decompressed byte strings the same [BYTES]?  True
#6 158.5 
#6 158.5 Testing size: 1MB
#6 158.5 Are the original and decompressed byte strings the same [TORCH]?  True
#6 158.5 Are the original and decompressed byte strings the same [BYTES]?  True
#6 158.5 
#6 158.5 Testing size: 1.01MB
#6 158.5 Are the original and decompressed byte strings the same [TORCH]?  True
#6 158.5 Are the original and decompressed byte strings the same [BYTES]?  True
#6 158.5 
#6 158.5 Testing size: 1.99MB
#6 158.5 Are the original and decompressed byte strings the same [TORCH]?  True
#6 158.5 Are the original and decompressed byte strings the same [BYTES]?  True
#6 158.5 
#6 158.5 Testing size: 2MB
#6 158.5 Are the original and decompressed byte strings the same [TORCH]?  True
#6 158.5 Are the original and decompressed byte strings the same [BYTES]?  True
#6 158.5 
#6 158.5 Testing size: 2.1MB
#6 158.5 Are the original and decompressed byte strings the same [TORCH]?  True
#6 158.5 Are the original and decompressed byte strings the same [BYTES]?  True
#6 158.5 
#6 158.5 Testing chunk size: 524288 Bytes
#6 158.5 Are the original and decompressed byte strings the same [STREAMING BYTES]?  True
#6 158.5 
#6 158.5 Testing chunk size: 1048576 Bytes
#6 158.5 Are the original and decompressed byte strings the same [STREAMING BYTES]?  True
#6 158.5 
#6 158.5 Testing chunk size: 2097152 Bytes
#6 158.5 Are the original and decompressed byte strings the same [STREAMING BYTES]?  True
#6 158.5 
#6 158.5 Testing chunk size: 8388608 Bytes
#6 158.5 Are the original and decompressed byte strings the same [STREAMING BYTES]?  True
#6 158.5 
#6 158.5 Testing chunk size: 16777216 Bytes
#6 158.5 Are the original and decompressed byte strings the same [STREAMING BYTES]?  True
#6 158.5 Are the original and decompressed byte strings the same [DELTA BUFFER]?  True
#6 158.5 Are the original and decompressed byte strings the same [STREAMING DELTA BUFFER]?  True
#6 158.5 Are the original and decompressed byte strings the same [DELTA FILE]?  True
#6 158.5 Are the original and decompressed byte strings the same [DELTA FILE STREAMING]?  True
#6 158.5 Are the original and decompressed float32 arrays the same [FLOAT32]?  True
#6 158.5 Are the original and decompressed float32 arrays the same [STREAMING FLOAT32]?  True
#6 158.5 Are the original and decompressed float32 arrays the same [STREAMING DELTA FLOAT32]?  True
#6 158.5 original length in bytes 1048576
#6 158.5 Check different standard option with different dtypes
#6 158.5 zstd byte /bytearray_dtype=float32/threads=1
#6 158.5 compress_ratio 0.77 compression_time = 0.003033876419067383 decompression_time 0.001323699951171875 original_len 1048576 method: zstd  input_format: byte  bytearray_dtype: float32  threads: 1 
#6 158.5 zstd torch / threads=1
#6 158.5 compress_ratio 0.77 compression_time = 0.0026769638061523438 decompression_time 0.0013556480407714844 original_len 1048576 method: zstd  input_format: torch  bytearray_dtype: float32  threads: 1 
#6 158.5 original length in bytes 1048576
#6 158.5 Check different standard option with different dtypes
#6 158.5 zstd byte /bytearray_dtype=bfloat16/threads=1
#6 158.5 compress_ratio 0.55 compression_time = 0.0030717849731445312 decompression_time 0.002012491226196289 original_len 1048576 method: zstd  input_format: byte  bytearray_dtype: bfloat16  threads: 1 
#6 158.5 zstd torch / threads=1
#6 158.5 compress_ratio 0.55 compression_time = 0.003173351287841797 decompression_time 0.0021216869354248047 original_len 1048576 method: zstd  input_format: torch  bytearray_dtype: bfloat16  threads: 1 
#6 158.5 original length in bytes 1048576
#6 158.5 Check different standard option with different dtypes
#6 158.5 zstd byte /bytearray_dtype=float16/threads=1
#6 158.5 compress_ratio 0.73 compression_time = 0.003028392791748047 decompression_time 0.002059459686279297 original_len 1048576 method: zstd  input_format: byte  bytearray_dtype: float16  threads: 1 
#6 158.5 zstd torch / threads=1
#6 158.5 compress_ratio 0.73 compression_time = 0.0042705535888671875 decompression_time 0.004553794860839844 original_len 1048576 method: zstd  input_format: torch  bytearray_dtype: float16  threads: 1 
#6 DONE 160.5s

#7 [4/5] RUN cd /repo && pytest --collect-only -q
#7 3.109 tests/test_one_model.py::test_zipnn
#7 3.109 tests/test_one_model.py::test_compression_decompression_float
#7 3.109 tests/test_suit.py::test_compression_decompression_float
#7 3.109 tests/test_suit.py::test_byte_torch_streaming
#7 3.109 tests/test_suit.py::TestSuite::test_byte_torch_streaming
#7 3.109 tests/test_suit.py::TestSuite::test_compression_decompression_float
#7 3.109 
#7 3.109 6 tests collected in 2.36s
#7 DONE 3.9s

#8 exporting to image
#8 exporting layers
#8 exporting layers 45.3s done
#8 writing image sha256:25af6a0403970147041b5951ccb3abb11ffc31264bab2690498487f49da7e0b5 done
#8 naming to docker.io/library/tmp:tmp done
#8 DONE 45.3s
