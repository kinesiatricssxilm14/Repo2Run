#0 building with "default" instance using docker driver

#1 [internal] load build definition from Dockerfile
#1 transferring dockerfile: 1.09kB done
#1 DONE 0.0s

#2 [internal] load metadata for docker.io/library/python:3.10
#2 DONE 0.0s

#3 [internal] load .dockerignore
#3 transferring context: 2B done
#3 DONE 0.0s

#4 [1/5] FROM docker.io/library/python:3.10
#4 DONE 0.0s

#5 [2/5] RUN mkdir -p ~/.pip && touch ~/.pip/pip.conf &&     echo "[global]" >> ~/.pip/pip.conf && echo "index-url=http://simple/" >> ~/.pip/pip.conf && echo "[install]" >> ~/.pip/pip.conf && echo "trusted-host=pypi..org" >> ~/.pip/pip.conf &&     apt-get update && apt-get install -y curl &&     curl -sSL https://install.python-poetry.org | python -
#5 CACHED

#6 [3/5] RUN pip install pytest pytest-xdist &&     pip install pipdeptree &&     git clone https://github.com/dingo-actual/infini-transformer.git &&     mkdir /repo &&     git config --global --add safe.directory /repo &&     cp -r /infini-transformer/. /repo && rm -rf /infini-transformer/ &&     rm -rf /infini-transformer &&     cd /repo && git checkout 08d0a128710cd37da3e7be15f00ec683716aea0f &&     pip install torch==2.5.1
#6 1.662 Looking in indexes: http://simple/
#6 1.821 Collecting pytest
#6 1.841   Downloading http://packages/pytest/pytest-8.3.4-py3-none-any.whl (343 kB)
#6 1.868      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 343.1/343.1 kB 16.3 MB/s eta 0:00:00
#6 1.944 Collecting pytest-xdist
#6 1.963   Downloading http://packages/pytest-xdist/pytest_xdist-3.6.1-py3-none-any.whl (46 kB)
#6 1.975      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.1/46.1 kB 4.9 MB/s eta 0:00:00
#6 2.035 Collecting iniconfig
#6 2.063   Downloading http://packages/iniconfig/iniconfig-2.0.0-py3-none-any.whl (5.9 kB)
#6 2.132 Collecting packaging
#6 2.151   Downloading http://packages/packaging/packaging-24.2-py3-none-any.whl (65 kB)
#6 2.164      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.5/65.5 kB 6.5 MB/s eta 0:00:00
#6 2.210 Collecting pluggy<2,>=1.5
#6 2.233   Downloading http://packages/pluggy/pluggy-1.5.0-py3-none-any.whl (20 kB)
#6 2.296 Collecting tomli>=1
#6 2.314   Downloading http://packages/tomli/tomli-2.2.1-py3-none-any.whl (14 kB)
#6 2.366 Collecting exceptiongroup>=1.0.0rc8
#6 2.387   Downloading http://packages/exceptiongroup/exceptiongroup-1.2.2-py3-none-any.whl (16 kB)
#6 2.450 Collecting execnet>=2.1
#6 2.473   Downloading http://packages/execnet/execnet-2.1.1-py3-none-any.whl (40 kB)
#6 2.486      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.6/40.6 kB 3.8 MB/s eta 0:00:00
#6 2.627 Installing collected packages: tomli, pluggy, packaging, iniconfig, execnet, exceptiongroup, pytest, pytest-xdist
#6 3.190 Successfully installed exceptiongroup-1.2.2 execnet-2.1.1 iniconfig-2.0.0 packaging-24.2 pluggy-1.5.0 pytest-8.3.4 pytest-xdist-3.6.1 tomli-2.2.1
#6 3.191 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
#6 3.316 
#6 3.316 [notice] A new release of pip is available: 23.0.1 -> 24.3.1
#6 3.316 [notice] To update, run: pip install --upgrade pip
#6 4.156 Looking in indexes: http://simple/
#6 4.242 Collecting pipdeptree
#6 4.262   Downloading http://packages/pipdeptree/pipdeptree-2.24.0-py3-none-any.whl (32 kB)
#6 4.411 Collecting pip>=24.2
#6 4.422   Using cached http://packages/pip/pip-24.3.1-py3-none-any.whl (1.8 MB)
#6 4.443 Requirement already satisfied: packaging>=24.1 in /usr/local/lib/python3.10/site-packages (from pipdeptree) (24.2)
#6 4.557 Installing collected packages: pip, pipdeptree
#6 4.557   Attempting uninstall: pip
#6 4.558     Found existing installation: pip 23.0.1
#6 4.748     Uninstalling pip-23.0.1:
#6 4.907       Successfully uninstalled pip-23.0.1
#6 6.323 Successfully installed pip-24.3.1 pipdeptree-2.24.0
#6 6.323 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
#6 6.521 Cloning into 'infini-transformer'...
#6 8.361 Note: switching to '08d0a128710cd37da3e7be15f00ec683716aea0f'.
#6 8.361 
#6 8.361 You are in 'detached HEAD' state. You can look around, make experimental
#6 8.361 changes and commit them, and you can discard any commits you make in this
#6 8.361 state without impacting any branches by switching back to a branch.
#6 8.361 
#6 8.361 If you want to create a new branch to retain commits you create, you may
#6 8.361 do so (now or later) by using -c with the switch command. Example:
#6 8.361 
#6 8.361   git switch -c <new-branch-name>
#6 8.361 
#6 8.361 Or undo this operation with:
#6 8.361 
#6 8.361   git switch -
#6 8.361 
#6 8.361 Turn off this advice by setting config variable advice.detachedHead to false
#6 8.361 
#6 8.361 HEAD is now at 08d0a12 removed mention of PoSE from readme
#6 8.898 Looking in indexes: http://simple/
#6 9.002 Collecting torch==2.5.1
#6 9.023   Downloading http://packages/torch/torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)
#6 24.37      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 906.4/906.4 MB 20.3 MB/s eta 0:00:00
#6 27.67 Collecting filelock (from torch==2.5.1)
#6 27.67   Using cached http://packages/filelock/filelock-3.16.1-py3-none-any.whl (16 kB)
#6 27.72 Collecting typing-extensions>=4.8.0 (from torch==2.5.1)
#6 27.74   Downloading http://packages/typing-extensions/typing_extensions-4.12.2-py3-none-any.whl (37 kB)
#6 27.81 Collecting networkx (from torch==2.5.1)
#6 27.83   Downloading http://packages/networkx/networkx-3.4.2-py3-none-any.whl (1.7 MB)
#6 27.88      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 48.0 MB/s eta 0:00:00
#6 27.94 Collecting jinja2 (from torch==2.5.1)
#6 27.96   Downloading http://packages/jinja2/jinja2-3.1.5-py3-none-any.whl (134 kB)
#6 28.03 Collecting fsspec (from torch==2.5.1)
#6 28.05   Downloading http://packages/fsspec/fsspec-2024.12.0-py3-none-any.whl (183 kB)
#6 28.15 Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1)
#6 28.17   Downloading http://packages/nvidia-cuda-nvrtc-cu12/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)
#6 28.31      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.6/24.6 MB 191.9 MB/s eta 0:00:00
#6 28.42 Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1)
#6 28.44   Downloading http://packages/nvidia-cuda-runtime-cu12/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)
#6 28.47      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 883.7/883.7 kB 39.6 MB/s eta 0:00:00
#6 28.51 Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1)
#6 28.53   Downloading http://packages/nvidia-cuda-cupti-cu12/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)
#6 28.63      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.8/13.8 MB 163.4 MB/s eta 0:00:00
#6 28.70 Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1)
#6 28.72   Downloading http://packages/nvidia-cudnn-cu12/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)
#6 33.82      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 63.7 MB/s eta 0:00:00
#6 36.29 Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1)
#6 36.32   Downloading http://packages/nvidia-cublas-cu12/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)
#6 38.73      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 363.4/363.4 MB 123.7 MB/s eta 0:00:00
#6 39.89 Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1)
#6 39.91   Downloading http://packages/nvidia-cufft-cu12/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)
#6 40.99      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.5/211.5 MB 198.7 MB/s eta 0:00:00
#6 41.68 Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1)
#6 41.70   Downloading http://packages/nvidia-curand-cu12/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)
#6 41.97      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 212.8 MB/s eta 0:00:00
#6 42.17 Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1)
#6 42.19   Downloading http://packages/nvidia-cusolver-cu12/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)
#6 42.92      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 127.9/127.9 MB 181.0 MB/s eta 0:00:00
#6 43.36 Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1)
#6 43.38   Downloading http://packages/nvidia-cusparse-cu12/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)
#6 44.73      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.5/207.5 MB 155.7 MB/s eta 0:00:00
#6 45.41 Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.1)
#6 45.43   Downloading http://packages/nvidia-nccl-cu12/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)
#6 46.53      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 188.7/188.7 MB 174.9 MB/s eta 0:00:00
#6 47.16 Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.5.1)
#6 47.18   Downloading http://packages/nvidia-nvtx-cu12/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)
#6 47.22 Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1)
#6 47.24   Downloading http://packages/nvidia-nvjitlink-cu12/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)
#6 47.41      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.1/21.1 MB 141.4 MB/s eta 0:00:00
#6 47.53 Collecting triton==3.1.0 (from torch==2.5.1)
#6 47.55   Downloading http://packages/triton/triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)
#6 48.82      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.5/209.5 MB 167.5 MB/s eta 0:00:00
#6 49.81 Collecting sympy==1.13.1 (from torch==2.5.1)
#6 49.83   Downloading http://packages/sympy/sympy-1.13.1-py3-none-any.whl (6.2 MB)
#6 49.92      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.2/6.2 MB 79.4 MB/s eta 0:00:00
#6 50.01 Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.5.1)
#6 50.03   Downloading http://packages/mpmath/mpmath-1.3.0-py3-none-any.whl (536 kB)
#6 50.05      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 22.7 MB/s eta 0:00:00
#6 50.19 Collecting MarkupSafe>=2.0 (from jinja2->torch==2.5.1)
#6 50.21   Downloading http://packages/markupsafe/MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)
#6 50.61 Installing collected packages: mpmath, typing-extensions, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch
#6 131.7 Successfully installed MarkupSafe-3.0.2 filelock-3.16.1 fsspec-2024.12.0 jinja2-3.1.5 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.1 triton-3.1.0 typing-extensions-4.12.2
#6 131.7 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
#6 DONE 136.1s

#7 [4/5] RUN cd /repo && pytest --collect-only -q
#7 2.968 tests/test_transformer.py::test_infini_transformer
#7 2.968 tests/test_transformer.py::test_mod_infini_transformer
#7 2.968 
#7 2.968 =============================== warnings summary ===============================
#7 2.968 ../usr/local/lib/python3.10/site-packages/torch/_subclasses/functional_tensor.py:295
#7 2.968   /usr/local/lib/python3.10/site-packages/torch/_subclasses/functional_tensor.py:295: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)
#7 2.968     cpu = _conversion_method_template(device=torch.device("cpu"))
#7 2.968 
#7 2.968 -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
#7 2.968 2 tests collected in 2.12s
#7 DONE 3.7s

#8 exporting to image
#8 exporting layers
#8 exporting layers 44.1s done
#8 writing image sha256:f291cecfee14cef5639c0329ae78ca4ef4adcb19f47199e737a86f3e04adf2b5 done
#8 naming to docker.io/library/tmp:tmp done
#8 DONE 44.2s
