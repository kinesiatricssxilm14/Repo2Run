tests/test_tokenizer.py::test_encode_decode_identity[-BasicTokenizer]
tests/test_tokenizer.py::test_encode_decode_identity[-RegexTokenizer]
tests/test_tokenizer.py::test_encode_decode_identity[-GPT4Tokenizer]
tests/test_tokenizer.py::test_encode_decode_identity[?-BasicTokenizer]
tests/test_tokenizer.py::test_encode_decode_identity[?-RegexTokenizer]
tests/test_tokenizer.py::test_encode_decode_identity[?-GPT4Tokenizer]
tests/test_tokenizer.py::test_encode_decode_identity[hello world!!!? (\uc548\ub155\ud558\uc138\uc694!) lol123 \U0001f609-BasicTokenizer]
tests/test_tokenizer.py::test_encode_decode_identity[hello world!!!? (\uc548\ub155\ud558\uc138\uc694!) lol123 \U0001f609-RegexTokenizer]
tests/test_tokenizer.py::test_encode_decode_identity[hello world!!!? (\uc548\ub155\ud558\uc138\uc694!) lol123 \U0001f609-GPT4Tokenizer]
tests/test_tokenizer.py::test_encode_decode_identity[FILE:taylorswift.txt-BasicTokenizer]
tests/test_tokenizer.py::test_encode_decode_identity[FILE:taylorswift.txt-RegexTokenizer]
tests/test_tokenizer.py::test_encode_decode_identity[FILE:taylorswift.txt-GPT4Tokenizer]
tests/test_tokenizer.py::test_gpt4_tiktoken_equality[]
tests/test_tokenizer.py::test_gpt4_tiktoken_equality[?]
tests/test_tokenizer.py::test_gpt4_tiktoken_equality[hello world!!!? (\uc548\ub155\ud558\uc138\uc694!) lol123 \U0001f609]
tests/test_tokenizer.py::test_gpt4_tiktoken_equality[FILE:taylorswift.txt]
tests/test_tokenizer.py::test_gpt4_tiktoken_equality_special_tokens
tests/test_tokenizer.py::test_wikipedia_example[BasicTokenizer]
tests/test_tokenizer.py::test_wikipedia_example[RegexTokenizer]
tests/test_tokenizer.py::test_save_load[special_tokens0]
tests/test_tokenizer.py::test_save_load[special_tokens1]

21 tests collected in 0.06s